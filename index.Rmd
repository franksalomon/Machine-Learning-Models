---
title: "Modelos Predictivos (c. 24/25)"
author: "Frank Salomon Sulca Palomino"
date: "21/03/2025"
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
  word_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r, echo=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```


## Motorcycle Data
```{r}
#############################################################################
# Propuesta: Obtener un modelo predictivo para los datos motorcycle.   
# Goal: Obtain a predictive model for motorcycle data
#############################################################################
library(MASS)
data(mcycle)
plot(mcycle)
names(mcycle)

max_value <- max(mcycle$times)
max_value
```
Se propone analizar estos datos, utilizando diferentes modelos predictivos paramÃ©tricos.

## A. Modelo ParamÃ©trico / Parametric Model
    
  
```{r}
require(boot)

# Definir el grado mÃ¡ximo del polinomio
maxdegree <- 20

# Vector para almacenar el error de validaciÃ³n cruzada
eep <- rep(NA, maxdegree)  

# CÃ¡lculo del error de validaciÃ³n cruzada para diferentes grados polinÃ³micos
for (grado in 1:maxdegree) {  
  model <- glm(accel ~ poly(times, grado), data = mcycle)  
  eep[grado] <- cv.glm(mcycle, model, K = 10)$delta[2]  
}

# Graficar los errores de validaciÃ³n cruzada
plot(eep, type = 'b', xlab = "Grado del polinomio", ylab = "Error de validaciÃ³n cruzada", main = "ValidaciÃ³n cruzada para modelos polinÃ³micos")


which.min(eep)
gr.opt<-which.min(eep)
gr.opt
gr.eep.opt<-min(eep)

# Mostrar el resultado
cat("El grado Ã³ptimo del polinomio es:", gr.opt, "\n")
cat("El error de validaciÃ³n cruzada mÃ­nimo es:", gr.eep.opt, "\n")

```

```{r}
## Inserta tu cÃ³digo para determinar el $m$ Ã³ptimo que minimiza el AIC. 
## Insert you code to determine the degree $m$ that minimices the AIC criterion

# Cargar paquetes necesarios
require(boot)
require(stats4)

# Definir rango de grados de polinomios
maxdegree <- 20  
m_values <- 1:maxdegree

# Crear data frame para almacenar resultados
results <- data.frame(H = m_values, df = NA, R.sq = NA, Adj.R.sq = NA, 
                      logLik = NA, `-2logLik` = NA, AIC = NA, BIC = NA)

# Calcular mÃ©tricas para cada grado de polinomio
aic_values <- numeric(maxdegree)

for (grado in m_values) {  
  model <- lm(accel ~ poly(times, grado), data = mcycle)
  summary_model <- summary(model)
  
  results[grado, 2:8] <- c(df.residual(model), summary_model$r.squared * 100, 
                           summary_model$adj.r.squared * 100, logLik(model), 
                           -2 * logLik(model), AIC(model), BIC(model))
  
  aic_values[grado] <- AIC(model)
}

# Determinar el grado Ã³ptimo que minimiza AIC
optimal_m <- results$H[which.min(results$AIC)]

# Graficar AIC vs. Grado del polinomio
plot(m_values, aic_values, type = "b", pch = 19, col = "blue",
     xlab = "Orden (m)", ylab = "AIC", main = "AIC vs. Grado del Polinomio")
points(optimal_m, min(aic_values), col = "red", pch = 19, cex = 1.5)

# Mostrar resultados en consola
print(results, row.names = FALSE)
cat("El valor Ã³ptimo de m que minimiza el AIC es:", optimal_m, "\n")


```


```{r}
## Compara grÃ¡ficamente los dos ajustes.
## Graphically compare the fits of the two models above.

m_values <- 1:20

# Calcular error de validaciÃ³n cruzada y AIC
eep_values <- sapply(m_values, function(m) cv.glm(mcycle, glm(accel ~ poly(times, m), data = mcycle), K = 10)$delta[2])

# Encontrar grados Ã³ptimos
optimal_m_eep <- which.min(eep_values)
optimal_m_aic <- which.min(aic_values)

# Graficar ambas mÃ©tricas
par(mfrow = c(1, 2))  
plot(m_values, eep_values, type = "b", pch = 19, col = "blue", xlab = "Grado del polinomio", 
     ylab = "Error de validaciÃ³n cruzada", main = "ValidaciÃ³n Cruzada")
points(optimal_m_eep, min(eep_values), col = "red", pch = 19, cex = 1.5)

plot(m_values, aic_values, type = "b", pch = 19, col = "blue", xlab = "Grado del polinomio", 
     ylab = "AIC", main = "Criterio AIC")
points(optimal_m_aic, min(aic_values), col = "red", pch = 19, cex = 1.5)

par(mfrow = c(1, 1))  
cat("Grado Ã³ptimo segÃºn validaciÃ³n cruzada:", optimal_m_eep, "\n")
cat("Grado Ã³ptimo segÃºn AIC:", optimal_m_aic, "\n")


```

```{r}
## Calcula el ECM de ambos modelos y comparÃ¡los.
## Compute the MSE of the two models.
# Ajustar los modelos con los grados Ã³ptimos
model_eep <- lm(accel ~ poly(times, optimal_m_eep), data = mcycle)
model_aic <- lm(accel ~ poly(times, optimal_m_aic), data = mcycle)

# Calcular predicciones
pred_eep <- predict(model_eep, newdata = mcycle)
pred_aic <- predict(model_aic, newdata = mcycle)

# Calcular ECM
ecm_eep <- mean((mcycle$accel - pred_eep)^2)
ecm_aic <- mean((mcycle$accel - pred_aic)^2)

# Comparar ECM
cat("ECM del modelo basado en validaciÃ³n cruzada:", ecm_eep, "\n")
cat("ECM del modelo basado en AIC:", ecm_aic, "\n")

# Determinar cuÃ¡l modelo es mejor
if (ecm_eep < ecm_aic) {
  cat("El modelo basado en validaciÃ³n cruzada tiene mejor ajuste.\n")
} else {
  cat("El modelo basado en AIC tiene mejor ajuste.\n")
}
 
```


### Reproducibilidad/Reproducibility

El uso de set.seed() en un cÃ³digo que involucra validaciÃ³n cruzada (cv.glm()) es crucial para garantizar que los resultados sean reproducibles y evitar resultados distintas cada ves que  se corra el codigo, 
Cada vez que ejecutas cv.glm(), la funciÃ³n divide los datos en diferentes grupos aleatorios (K = 10 particiones en este caso). Sin embargo, si no fijas una semilla (set.seed()), las particiones cambiarÃ¡n, lo que puede dar valores de error de validaciÃ³n cruzada ligeramente diferentes.


```{r}
miNIP<- 934297 ## asigna tu NIP a esta variable. Lo usaremos como semilla de aletarizaciÃ³n
        ## assign your NIP to this variable. It will be used as a random seed.

```



```{r}
library(boot)

miNIP <- 934297
set.seed(miNIP)  # ðŸ”¹ Asegura reproducibilidad en las particiones aleatorias

max_degree <- 20# MÃ¡ximo grado del polinomio
cv_errores <- numeric(max_degree)  # Vector para almacenar los errores

# CÃ¡lculo de errores de validaciÃ³n cruzada para diferentes grados de polinomio
for (m in 1:max_degree) {
  formula <- as.formula(paste("accel ~ poly(times,", m, ")"))
  cv_errores[m] <- cv.glm(mcycle, glm(formula, data = mcycle), K = 10)$delta[2]
}

# Graficar los errores de validaciÃ³n cruzada
plot(1:max_degree, cv_errores, type = 'b', xlab = 'Grado del polinomio', ylab = 'Error de CV')

# Encontrar el grado Ã³ptimo
gr_optimo <- which.min(cv_errores)
error_minimo <- min(cv_errores)

cat("El grado Ã³ptimo del polinomio es:", gr_optimo, "\n")
cat("El error mÃ­nimo de validaciÃ³n cruzada es:", error_minimo, "\n")


```

### Ampliando los Polinomios/Expanding Polynomials


Esta funciÃ³n toma dos parÃ¡metros: x (los valores a transformar) y c (el umbral, por defecto 0). La operaciÃ³n ReLU calcula la diferencia entre cada valor de x y c, y toma el mÃ¡ximo entre esa diferencia y 0. Si x es menor que c, se convierte en 0; si es mayor, se le resta c.
Por ejemplo, con una secuencia de -5 a 5 y un umbral de 3, los valores â‰¤ 3 se transforman en 0, y los mayores a 3 se les resta 3. El resultado se guarda en y_test.


```{r}
# Cargar la librerÃ­a MASS para usar mcycle
library(MASS)

# Definir la funciÃ³n ReLu
ReLu <- function(x, c = 0) {
  pmax(x - c, 0)
}

# 1. Prueba simple con valores arbitrarios
x_test <- -5:5
y_test <- ReLu(x_test, 3)
print(y_test)  # Muestra cÃ³mo se transforma x_test




####Ahora aplicamos la funcion ReLu a la data real (mcycle)
x_vals <- mcycle$times  # Variable predictora
y_vals <- mcycle$accel  # Variable de respuesta


# Transformar con ReLu usando un umbral c = 20
x_transf <- ReLu(x_vals, c = 20)

# Graficar datos originales
plot(x_vals, y_vals, pch = 16, col = "gray", main = "AplicaciÃ³n de ReLu a mcycle",
     xlab = "Tiempo (ms)", ylab = "AceleraciÃ³n (g)", cex = 0.8)

# Graficar transformaciÃ³n
points(x_vals, x_transf, col = "red", pch = 16, cex = 0.6)

# Agregar una lÃ­nea vertical en c = 20
abline(v = 20, col = "blue", lwd = 2, lty = 2)

legend("topleft", legend = c("Datos originales", "Datos transformados con ReLu"),
       col = c("gray", "red"), pch = 16)


```

Comentario: Usamos la funciÃ³n ` ReLu(x,c)` combinada con la funciÃ³n `poly` para obtener un modelo mÃ¡s parsimonioso. El comportamiento de esta funciÃ³n puede servir para simplificar la parte inicial del modelo donde los datos presentan poca variabilidad y una aceleraciÃ³n casi nula en los primeros instantes, antes de la fase de desaceleraciÃ³n debida al impacto.


Ahora, tenemos que fijar/seleccionar dos parÃ¡metros, `c` y $m$, el grado del polinomio. 

Vamos a seleccionar ambos parÃ¡metros de nuevo por CV.


### ajuste de c /  tuning `c`  value

Para ganar experiencia, SE fija un valor de $m$, por ejemplo $m=5$ y se intenta obtener por CV el valor Ã³ptimo de $c$.



```{r}

require(boot)

# Valores de c a evaluar
cvalues <- seq(11, 15, 0.1)  # Estos valores pueden ajustarse segÃºn se necesite

# InicializaciÃ³n del vector para guardar los errores de validaciÃ³n cruzada
eep <- rep(NA, length(cvalues))

# Fijamos el grado del polinomio
grado <- 5  # Se puede cambiar el valor de 'grado' para experimentar con otros valores

# Realizamos la validaciÃ³n cruzada para cada valor de 'c'
for (c in cvalues) {
  # Definir la fÃ³rmula que incluye el tÃ©rmino polinÃ³mico y la funciÃ³n ReLU
  formula <- as.formula(paste("accel ~ poly(times, ", grado, ") + ReLu(times, c)", sep = ""))   # Sin interacciÃ³n
  
  # Calcular el error de validaciÃ³n cruzada usando cv.glm
  eep[match(c, cvalues)] <- cv.glm(mcycle, glm(formula, data = mcycle), K = 5)$delta[2]
}

# Graficamos los errores de validaciÃ³n cruzada (eep) frente a los valores de 'c'
plot(cvalues, eep, type = 'b', xlab = 'Valor de c', ylab = 'Error de ValidaciÃ³n Cruzada (CV Error)')

# Encontramos el valor de 'c' que minimiza el error
c.opt <- which.min(eep)
cvalues[c.opt]  # Valor Ã³ptimo de 'c'
c.eep.opt <- min(eep)  # Error mÃ­nimo de validaciÃ³n cruzada

# Resumen del modelo con el valor Ã³ptimo de 'c'
best_model<- glm(as.formula(paste("accel ~ poly(times, ", grado, ") + ReLu(times, cvalues[c.opt])", sep = "")), data = mcycle)

# Imprimir el resumen del modelo y el valor Ã³ptimo de 'c'
cat("Resumen del modelo con el valor Ã³ptimo de 'c':\n")
summary(best_model)
cat("\nValor Ã³ptimo de 'c':", cvalues[c.opt], "\n")
cat("Error mÃ­nimo de validaciÃ³n cruzada:", c.eep.opt, "\n")

#c.opt <- which.min(eep) â†’ devuelve la posiciÃ³n (Ã­ndice) del valor mÃ­nimo.
#c.eep.opt <- min(eep) â†’ devuelve el valor mÃ­nimo mismo.
```

```{r}
## resumen del modelo que has obtenido
## summarizes your model for the best 'c' value
#summary(best_model)


```




Antes de continuar, recordemos que queremos un modelo que hasta un cierto instante $c_0$ sea plano y muy prÃ³ximo a $0$ y que luego recoja la desaceleraciÃ³n observada. Con esta idea se analiza la matriz del diseÃ±o que se obtiene de estas dos fÃ³rmulas y se elige la que puede ser mejor para representar esta modelizaciÃ³n.

formula1 <-  accel~ReLu(times,15)*poly(times,3)`
fomrula2<- accel~-1+ ReLu(times,15) +ReLu(times,15):poly(times,3)` 


```{r}
## CÃ³digo para obtener la matriz del diseÃ±o asociada a formula1

# Definir la primera fÃ³rmula
formula1 <- accel ~ ReLu(times, 12.2) * poly(times, 5)

# Calcular la matriz del diseÃ±o para formula1
X1 <- model.matrix(formula1, data = mcycle)

# Visualizar la matriz del diseÃ±o
head(X1)  # Mostrar las primeras filas de la matriz del diseÃ±o


## Idem para la matriz del diseÃ±o asociada a formula2


# Definir la segunda fÃ³rmula
formula2 <- accel ~ -1 + ReLu(times, 12.2) + ReLu(times, 12.2):poly(times, 5)

# Calcular la matriz del diseÃ±o para formula2
X2 <- model.matrix(formula2, data = mcycle)

# Visualizar la matriz del diseÃ±o
head(X2)  # Mostrar las primeras filas de la matriz del diseÃ±o

```




Se elige una de las dos tipos de fÃ³rmulas y vuelve a seleccionar `c` por CV utilizando un modelo en el que la funciÃ³n `ReLu`interactÃºe con `poly` (se mantiene el grado 5 de momento).



```{r}
### Introduce tu cÃ³digo para seleccionar 'c' por CV en modelos de interacciÃ³n entre `ReLu` y `poly`
### Write you code to select 'c' by CV in models with interaction terms of 'ReLu' and 'poly' functions

require(boot)
require(ggplot2)

# Definir el rango de valores para 'c'
cvalues <- seq(10, 15, 0.1)

# Calcular error de validaciÃ³n cruzada (CV) para cada 'c'
eep <- sapply(cvalues, function(c) {
  formula <- accel ~ ReLu(times, c): poly(times, 5)
  cv.glm(mcycle, glm(formula, data = mcycle), K = 5)$delta[2]
})

# Graficar error de validaciÃ³n cruzada
plot(cvalues, eep, type = 'b', xlab = "Valor de c", ylab = "Error de CV", main = "SelecciÃ³n de c por CV")

# Obtener el valor Ã³ptimo de 'c'
c.opt <- cvalues[which.min(eep)]
print(paste("Valor Ã³ptimo de c:", c.opt))

# Ajustar el modelo final con el c Ã³ptimo
model <- glm(accel ~ ReLu(times, c.opt): poly(times, 5), data = mcycle)

# Predicciones
mcycle$pred <- predict(model, newdata = mcycle)

# Graficar resultados
ggplot(mcycle, aes(x = times, y = accel)) + 
  geom_point(color = "black", alpha = 0.5, size = 1.5) +  # Datos originales
  geom_line(aes(y = pred, color = "Modelo ReLu:Poly"), size = 1) +  # PredicciÃ³n
  scale_color_manual(name = "Modelos", values = c("Modelo ReLu:Poly" = "blue")) +
  labs(x = "Tiempo", y = "AceleraciÃ³n", title = "Ajuste del Modelo ReLu:Poly con c Ã³ptimo") +
  theme_minimal()



```
Captura de efectos combinados: Al introducir una interacciÃ³n, el modelo puede capturar relaciones mÃ¡s complejas entre las dos variables (ReLu(times, c) y poly(times, 5)). Esto puede llevar a una mejora en la precisiÃ³n del modelo, ya que no solo estÃ¡s considerando los efectos individuales de estas dos transformaciones, sino tambiÃ©n cÃ³mo se combinan para influir en la variable dependiente (en este caso, accel).

 Mejor ajuste del modelo: Al permitir que el modelo considere cÃ³mo estos tÃ©rminos se combinan, podrÃ­as obtener un modelo mÃ¡s ajustado a los datos, lo que a su vez puede reducir el error de validaciÃ³n cruzada y mejorar la capacidad predictiva.

```{r}

# La primera matriz (formula1) es la mejor opciÃ³n, ya que mantiene la respuesta cerca de 0 antes de c0 , pero permite un ajuste mÃ¡s flexible de la desaceleraciÃ³n observada gracias a su estructura polinÃ³mica y la interacciÃ³n con ReLu(times, 12.2).

require(boot)
require(ggplot2)

# Define el rango de valores para 'c'
cvalues <- seq(10, 15, 0.1)

# Crear un marco de datos vacÃ­o para los resultados
results <- data.frame(c = rep(cvalues, each = 2), 
                      error = numeric(length(cvalues) * 2),
                      type = rep(c("ReLu(times, c): poly(times, 5)", "ReLu(times, c) * poly(times, 5)"), each = length(cvalues)))

# Calcular el error de CV para cada especificaciÃ³n de la interacciÃ³n
for (i in 1:length(cvalues)) {
  c <- cvalues[i]
  
  # Modelo con interacciÃ³n estÃ¡ndar
  formula1 <- accel ~ ReLu(times, c): poly(times, 5)
  eep1 <- cv.glm(mcycle, glm(formula1, data = mcycle), K = 5)$delta[2]
  
  # Modelo con interacciÃ³n explÃ­cita (sin efectos principales)
  formula2 <- accel ~ ReLu(times, c) * poly(times, 5)
  eep2 <- cv.glm(mcycle, glm(formula2, data = mcycle), K = 5)$delta[2]
  
  # Guardar los resultados
  results$error[results$c == c & results$type == "ReLu(times, c): poly(times, 5)"] <- eep1
  results$error[results$c == c & results$type == "ReLu(times, c) * poly(times, 5)"] <- eep2
}

# Graficar los resultados
ggplot(results, aes(x = c, y = error, color = type)) + 
  geom_line() + 
  geom_point() +
  labs(x = "Valor de c", y = "Error de CV", title = "ComparaciÃ³n de Interacciones: ReLu y Poly") +
  theme_minimal() +
  theme(legend.title = element_blank())

# Ajuste de los modelos con el valor Ã³ptimo de 'c'
# Determinar el mejor valor de 'c'
optimal_result <- results[which.min(results$error), ]
c.opt <- optimal_result$c  # Valor Ã³ptimo de 'c'
model.best.type <- optimal_result$type  # Mejor modelo segÃºn CV

# Ajustar ambos modelos con el valor Ã³ptimo de 'c'
model1 <- glm(accel ~ ReLu(times, c.opt): poly(times, 5), data = mcycle)
model2 <- glm(accel ~ ReLu(times, c.opt) * poly(times, 5), data = mcycle)

# Calcular ECM
ecm1 <- mean((mcycle$accel - predict(model1, newdata = mcycle))^2)
ecm2 <- mean((mcycle$accel - predict(model2, newdata = mcycle))^2)

# Determinar el mejor modelo segÃºn ECM
best.model <- ifelse(ecm1 < ecm2, "ReLu(times, c): poly(times, 5)", "ReLu(times, c) * poly(times, 5)")

# Mostrar los resultados
cat("Mejor modelo segÃºn CV: ", model.best.type, "\n")
cat("ECM del modelo 1: ", ecm1, "\n")
cat("ECM del modelo 2: ", ecm2, "\n")
cat("Mejor modelo segÃºn ECM: ", best.model, "\n")

# Predicciones de ambos modelos
pred1 <- predict(model1, newdata = mcycle)
pred2 <- predict(model2, newdata = mcycle)

# Graficar los resultados con la data original
ggplot(mcycle, aes(x = times, y = accel)) + 
  geom_point(color = "black", alpha = 0.5, size = 1.5) +  # Datos originales
  geom_line(aes(y = pred1, color = "ReLu(times, c): poly(times, 5)"), linetype = "dashed", size = 1) +  # PredicciÃ³n del modelo 1
  geom_line(aes(y = pred2, color = "ReLu(times, c) * poly(times, 5)"), linetype = "dotted", size = 1) +  # PredicciÃ³n del modelo 2
  labs(x = "Times", y = "Acceleration", title = "Ajuste de Modelos: ComparaciÃ³n de Predicciones") +
  scale_color_manual(name = "Modelos", values = c("ReLu(times, c): poly(times, 5)" = "blue", "ReLu(times, c) * poly(times, 5)" = "red")) +
  theme_minimal() 

```


Se compara el ajuste que obtienes ahora con el que has obtenido en el primer apartado. 


```{r}
### Presenta el valor del error de predicciÃ³n estimado (por CV) de este modelo Ãºltimo y del primer modelo polinÃ³mico que has ajustado (con m seleccionado por CV). ComÃ©nta los valores. 

### TambiÃ©n puedes aÃ±adir algÃºn grÃ¡fico que permita la comparaciÃ³n si lo crees conveniente.

require(boot)

# Valores de c a evaluar
cvalues <- seq(11, 15, 0.1)
eep <- sapply(cvalues, function(c) {
  formula <- accel ~ poly(times, 5) + ReLu(times, c)  # Sin interacciÃ³n
  cv.glm(mcycle, glm(formula, data = mcycle), K = 5)$delta[2]
})

# Encontrar el valor Ã³ptimo de 'c'
c.opt <- cvalues[which.min(eep)]
c.opt 
c.eep.opt <- min(eep)  # Error mÃ­nimo de validaciÃ³n cruzada
c.eep.opt 

# EvaluaciÃ³n del modelo con interacciÃ³n entre 'ReLu' y 'poly'
eep_interaction <- sapply(cvalues, function(c) {
  formula <- accel ~ ReLu(times, c): poly(times, 5)  # InteracciÃ³n entre ReLu y poly
  cv.glm(mcycle, glm(formula, data = mcycle), K = 5)$delta[2]
})

# Encontrar el valor Ã³ptimo de 'c' para este modelo
c.opt_interaction <- cvalues[which.min(eep_interaction)]
c.eep.opt_interaction <- min(eep_interaction)  # Error mÃ­nimo de validaciÃ³n cruzada
c.opt_interaction
c.eep.opt_interaction 


```

```{r}
### Calculate the value of the estimated prediction error (by CV) of this last model and of the first polynomial model you have fitted (with m selected by CV). Comment on these values.  

### You can also add some graphs to allow visual comparison.
# Comparar los errores de validaciÃ³n cruzada entre los dos modelos
barplot(c(c.eep.opt, c.eep.opt_interaction), 
        names.arg = c("Modelo sin interacciÃ³n", "Modelo con interacciÃ³n"), 
        col = c("lightblue", "lightgreen"), 
        ylab = "Error de validaciÃ³n cruzada", 
        main = "ComparaciÃ³n de errores de validaciÃ³n cruzada")


```



Se escribe el cÃ³digo para seleccionar la mejor combinaciÃ³n de $c$ y $m$ por CV conjunta.


```{r}
# Cargar librerÃ­as necesarias
library(boot)   # Para cv.glm
library(ggplot2) # Para la visualizaciÃ³n
library(caret)   # Para trainControl

# Definir valores de c y m
cvalues <- seq(10, 30, 0.5)
mvalues <- seq(5, 15, 0.5)

# Crear matriz de errores
eep_matrix <- matrix(NA, nrow = length(cvalues), ncol = length(mvalues),
                     dimnames = list(cvalues, mvalues))

# Definir el control de validaciÃ³n cruzada
fitControl <- trainControl(method = "cv", number = 10)

# FunciÃ³n de validaciÃ³n cruzada
eval_model <- function(c, m, data) {
  formula <- accel ~ ReLu(times, c) * poly(times, m)
  return(cv.glm(data, glm(formula, data = data), K = fitControl$number)$delta[2])
}
```

```{r}
# Llenar la matriz de errores
for (i in seq_along(cvalues)) {
  for (j in seq_along(mvalues)) {
    eep_matrix[i, j] <- eval_model(cvalues[i], mvalues[j], mcycle)
  }
}
```

```{r}
# Encontrar los valores Ã³ptimos de c y m
opt_idx <- which(eep_matrix == min(eep_matrix), arr.ind = TRUE)
c.opt <- as.numeric(rownames(eep_matrix)[opt_idx[1]])
m.opt <- as.numeric(colnames(eep_matrix)[opt_idx[2]])
eep.opt <- min(eep_matrix)

# Crear el dataframe para la visualizaciÃ³n
eep_df <- expand.grid(c = cvalues, m = mvalues)
eep_df$error <- as.vector(eep_matrix)

# VisualizaciÃ³n del error
scatter_plot <- ggplot(eep_df, aes(x = c, y = m, size = error, color = error)) +
  geom_point(alpha = 0.7) +
  scale_color_gradient(low = "blue", high = "red") +
  geom_point(aes(x = c.opt, y = m.opt), color = "black", size = 4, shape = 8) +
  annotate("text", x = c.opt, y = m.opt, label = paste0("c = ", c.opt, "\nm = ", m.opt, "\nError = ", round(eep.opt, 3)),
           color = "black", hjust = -0.2, vjust = -0.5) +
  labs(title = "Error de ValidaciÃ³n Cruzada", x = "Valor de c", y = "Valor de m") +
  theme_minimal()

print(scatter_plot)

# Ajustar y predecir con el modelo final
final_model <- glm(accel ~ ReLu(times, c.opt) * poly(times, m.opt), data = mcycle)
mcycle$pred <- predict(final_model, newdata = mcycle)

# Graficar modelo final
final_plot <- ggplot(mcycle, aes(x = times, y = accel)) +
  geom_point(color = "black", alpha = 0.5, size = 1.5) +
  geom_line(aes(y = pred, color = "Modelo Ã“ptimo"), size = 1) +
  scale_color_manual(name = "Modelo", values = c("Modelo Ã“ptimo" = "blue")) +
  labs(x = "Times", y = "Acceleration", title = "Ajuste del Modelo Ã“ptimo") +
  theme_minimal()

print(final_plot)






```




## B. MÃ­nimos Cuadrados Regularizados /Regularized Least Squares

Se aplica alguna de las funciones de mÃ­nimos cuadrados regularizados  (RLS) (p.ej. tipo `lasso`),

- aplica RLS al modelo polinÃ³mico bÃ¡sico        
- aplica tb. RLS al modelo propuesto que incorpora la funciÃ³n `ReLu`. 
`


En ambos casos, hay que determinar un valor de $\lambda$  de penalizaciÃ³n sobre los coeficientes del modelo, y de nuevo se realiza por CV.



```{r}
## Inserta tu cÃ³digo para determinar el $\lambda$ Ã³ptimo para el modelo MCP (tipo lasso) a partir del modelo polinÃ³mico puro.

# Instalar y cargar la librerÃ­a glmnet si no estÃ¡ instalada
if (!require("glmnet")) install.packages("glmnet")
library(glmnet)

# PreparaciÃ³n de los datos
# Se crea una matriz de caracterÃ­sticas con los tÃ©rminos polinÃ³micos del variable 'times'
x <- model.matrix(accel ~ poly(times, 5), data = mcycle)[, -1]  # Eliminamos la columna del intercepto, ya que glmnet la maneja internamente
y <- mcycle$accel  # La variable dependiente es 'accel'

# AplicaciÃ³n de Lasso al modelo polinÃ³mico (con 5 grados)
cv_lasso_poly <- cv.glmnet(x, y, alpha = 1)  # Realizamos Lasso con validaciÃ³n cruzada

# Graficamos los resultados para visualizar cÃ³mo cambia el error en funciÃ³n de lambda
plot(cv_lasso_poly)

# Mostrar el valor Ã³ptimo de lambda (el que minimiza el error)
lambda_opt_poly <- cv_lasso_poly$lambda.min
cat("Valor Ã³ptimo de lambda para el modelo polinÃ³mico:", lambda_opt_poly, "\n")
```



```{r}

## Inserta tu cÃ³digo para determinar el $\lambda$ Ã³ptimo para el modelo MCP (tipo lasso) a partir del modelo polinÃ³mico y su interacciÃ³n con la funciÃ³n `ReLu`

library(glmnet)

# Crear la funciÃ³n ReLu sobre 'times'
ReLu <- function(x, c) {
  pmax(0, x - c)  # ReLu aplicada a x con parÃ¡metro c
}


# AplicaciÃ³n de Lasso al modelo con ReLu
x_relu <- model.matrix(accel ~ ReLu(times, c.opt) * poly(times, m.opt), data = mcycle)[, -1]
cv_lasso_relu <- cv.glmnet(x_relu, y, alpha = 1)
plot(cv_lasso_relu)

lambda_opt_relu_poly <- cv_lasso_relu$lambda.min
lambda_opt_relu_poly

# ComparaciÃ³n de ambos modelos
cat("\nResumen de ambos modelos con sus valores Ã³ptimos de lambda:\n")
cat("Modelo PolinÃ³mico: ", lambda_opt_poly, "\n")  # AsegÃºrate de haber definido lambda_opt_poly previamente
cat("Modelo ReLu + PolinÃ³mico: ", lambda_opt_relu_poly, "\n")


```

```{r}

## Presenta alguna estimaciÃ³n del error o grÃ¡fico que permita comparar el grado de similitud de estos dos 
## modelos ajustados con su correspondiente $\lambda$ optimizado o seleccionado.
    
    # Primero definimos el valor Ã³ptimo de lambda para el modelo con ReLU
    lambda_opt_relu_poly <- cv_lasso_relu$lambda.min
    cat("Valor Ã³ptimo de lambda para el modelo ReLu + PolinÃ³mico:", lambda_opt_relu_poly, "\n")
    
    # Predicciones del modelo polinÃ³mico
    pred_poly <- predict(cv_lasso_poly, s = lambda_opt_poly, newx = x, type = "response")
    
    # Predicciones del modelo ReLU + PolinÃ³mico
    pred_relu_poly <- predict(cv_lasso_relu, s = lambda_opt_relu_poly, newx = x_relu, type = "response")

# Graficamos las predicciones versus los valores observados
par(mfrow = c(1, 2))  # Para graficar dos grÃ¡ficos en una sola ventana

# GrÃ¡fico para el modelo polinÃ³mico
plot(mcycle$times, mcycle$accel, main = "Modelo PolinÃ³mico", 
     xlab = "Tiempo", ylab = "AceleraciÃ³n", pch = 19, col = "blue")
lines(mcycle$times, pred_poly, col = "red", lwd = 2)

# GrÃ¡fico para el modelo ReLU + PolinÃ³mico
plot(mcycle$times, mcycle$accel, main = "Modelo ReLU + PolinÃ³mico", 
     xlab = "Tiempo", ylab = "AceleraciÃ³n", pch = 19, col = "blue")
lines(mcycle$times, pred_relu_poly, col = "green", lwd = 2)

# Calcular el error cuadrÃ¡tico medio (MSE) de ambos modelos
mse_poly <- mean((mcycle$accel - pred_poly)^2)
mse_relu_poly <- mean((mcycle$accel - pred_relu_poly)^2)

# Mostrar los errores
cat("\nError cuadrÃ¡tico medio (MSE) del modelo polinÃ³mico:", mse_poly, "\n")
cat("Error cuadrÃ¡tico medio (MSE) del modelo ReLU + PolinÃ³mico:", mse_relu_poly, "\n")

```



## PredicciÃ³n extra-muestral

Hemos ajustado varios modelos, en los que hemos calculado el ECM dentro del rango de valores observados. En esta Ãºltima parte vamos a comparar los modelos por su comportamiento fuera del rango de valores observados, para instantes mayores a los observados. 


- Se define una secuencia de nuevos datos mayores que el mÃ¡ximo de `times` y predice con cada uno de los modelos. Por ejemplo, para estimar la aceleraciÃ³n hasta el instante $times=70$ en al menos $20$ valores intermedios entre el mÃ¡ximo de la muestra y $70$.
- Se valora  (grÃ¡fica o numÃ©ricamente) si algÃºn modelo estÃ¡ capturando que al aumentar el tiempo la aceleraciÃ³n deberÃ­a tender de nuevo a $0$ (en ausencia de otra nueva fuerza sobre el objeto).



**Para que el modelo tienda a 0 se optÃ³ por definir el valor de lambda y asi obtener un decaimiento exponencial**


```{r}

# Definir el valor de lambda (se optÃ³ por ajustar el valor de lambda para obtener un decaimiento exponencial)
lambda <- 0.05

# Rango de nuevos tiempos (extra-muestrales)
new_times <- seq(max(mcycle$times), 90, length.out = 20)

# Predicciones con el modelo polinÃ³mico
pred_poly <- predict(cv_lasso_poly, s = lambda_opt_poly, 
                     newx = model.matrix(~ poly(new_times, 5), data.frame(times = new_times))[, -1])

# Predicciones con el modelo ReLU
pred_relu <- predict(cv_lasso_relu, s = lambda_opt_relu_poly, 
                     newx = model.matrix(~ ReLu(new_times, c.opt) * poly(new_times, m.opt), data.frame(times = new_times))[, -1])

# Data frame con las predicciones sin decaimiento exponencial
predictions_df <- data.frame(times = new_times, pred_poly = pred_poly, pred_relu = pred_relu)

# Renombrar las columnas
colnames(predictions_df) <- c("times", "PredicciÃ³n_PolinÃ³mico", "PredicciÃ³n_ReLU_PolinÃ³mico")

# Ordenar el data frame
predictions_df <- predictions_df[order(predictions_df$times), ]

# Mostrar el data frame con las predicciones sin decaimiento exponencial
print(predictions_df)

# Graficar las predicciones sin decaimiento exponencial
plot(mcycle$times, mcycle$accel, xlim = c(min(mcycle$times), 70), 
     ylim = range(c(mcycle$accel, pred_poly, pred_relu)), 
     main = 'PredicciÃ³n Extra-muestral', xlab = 'Tiempo', ylab = 'AceleraciÃ³n')
lines(new_times, pred_poly, col = 'blue', lwd = 2, lty = 2)
lines(new_times, pred_relu, col = 'green', lwd = 2, lty = 2)
legend('bottomleft', legend = c('Modelo PolinÃ³mico', 'Modelo ReLU'), col = c('blue', 'green'), lwd = 2, lty = 2)

# Aplicar el decaimiento exponencial a las predicciones
pred_poly_decay <- pred_poly * exp(-lambda * new_times)
pred_relu_decay <- pred_relu * exp(-lambda * new_times)

# Graficar las predicciones con el decaimiento exponencial
plot(mcycle$times, mcycle$accel, xlim = c(min(mcycle$times), 70), 
     ylim = range(c(mcycle$accel, pred_poly_decay, pred_relu_decay)), 
     main = 'PredicciÃ³n Extra-muestral con Decaimiento Exponencial', 
     xlab = 'Tiempo', ylab = 'AceleraciÃ³n')
lines(new_times, pred_poly_decay, col = 'blue', lwd = 2, lty = 2)
lines(new_times, pred_relu_decay, col = 'green', lwd = 2, lty = 2)
legend('bottomleft', legend = c('Modelo PolinÃ³mico', 'Modelo ReLU'), col = c('blue', 'green'), lwd = 2, lty = 2)

# Data frame con las predicciones con decaimiento exponencial
predictions_df2 <- data.frame(times = new_times, pred_poly = pred_poly_decay, pred_relu = pred_relu_decay)

# Renombrar las columnas
colnames(predictions_df2) <- c("times", "PredicciÃ³n_PolinÃ³mica_Con_Decaimiento", "PredicciÃ³n_ReLU_Con_Decaimiento")

# Mostrar el data frame con las predicciones con decaimiento exponencial
print(predictions_df2)


```


